{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2001.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2002.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2003.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2004.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2005.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2006.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2007.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2008.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2009.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\201.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2010.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2011.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2012.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2013.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2014.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2015.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2016.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2017.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2018.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2019.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\202.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2020.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2021.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2022.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\2023.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\211.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\212.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\213.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\214.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\215.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\216.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\217.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\218.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\219.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\222.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\250.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\261.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\262.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\263.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\264.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\265.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\266.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\267.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\268.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\269.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\270.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\271.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\272.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\273.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\274.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\275.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\276.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\277.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\278.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\279.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\280.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\281.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\282.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\283.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\284.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\285.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\286.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\287.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\288.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\289.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\290.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\291.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\292.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\293.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\294.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\295.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\296.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\297.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\298.txt', 'C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire\\\\299.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob(\"C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire/*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def somthing(path):\n",
    "    list=[]\n",
    "    for i in glob.glob(path) :\n",
    "        file= open(i, 'r')\n",
    "        data = file.read().replace('\\n', '')\n",
    "        list.append(data)\n",
    "    return (list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=somthing(\"C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire/*.txt\")\n",
    "y=somthing(\"C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Satire_titles/*.txt\")\n",
    "xr=somthing(\"C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Real/*.txt\")\n",
    "yr=somthing(\"C:/Users/hedi/Desktop/factory619 internship/satir detection/data/Real_titles/*.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp=pd.DataFrame({'text':x,'satire':1})\n",
    "dpr=pd.DataFrame({'text':xr,'satire':0})\n",
    "df = pd.concat([dp, dpr], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>satire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>Aisha Alfa reports on the Kathleen Wynne gover...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  satire\n",
       "64  Aisha Alfa reports on the Kathleen Wynne gover...       1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>satire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A federal board responsible for protecting Ame...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TORONTO – The emergence of EQAO test results t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GREENSBORO, N.C. (The Borowitz Report)—Hillary...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Congressional Republicans have largely sought ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WASHINGTON (The Borowitz Report)—Calling his a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>NEW YORK (The Borowitz Report)—Republicans on ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>Michelle Obama in a candid interview with Opra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>KIEV, UKRAINE (SatireWire.com) — Leaders from ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>A former top official at the country's third-l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>WASHINGTON — The FBI warrant that shook Hillar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  satire\n",
       "0    A federal board responsible for protecting Ame...       0\n",
       "1    TORONTO – The emergence of EQAO test results t...       1\n",
       "2    GREENSBORO, N.C. (The Borowitz Report)—Hillary...       1\n",
       "3    Congressional Republicans have largely sought ...       0\n",
       "4    WASHINGTON (The Borowitz Report)—Calling his a...       1\n",
       "..                                                 ...     ...\n",
       "145  NEW YORK (The Borowitz Report)—Republicans on ...       1\n",
       "146  Michelle Obama in a candid interview with Opra...       0\n",
       "147  KIEV, UKRAINE (SatireWire.com) — Leaders from ...       1\n",
       "148  A former top official at the country's third-l...       0\n",
       "149  WASHINGTON — The FBI warrant that shook Hillar...       0\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n",
      "Test Accuracy: 0.867\n",
      "Precision: 0.917\n",
      "Recall: 0.786\n",
      "F1: 0.846\n",
      "[[15  1]\n",
      " [ 3 11]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#low range of data so still in process\n",
    "\n",
    "text_train, text_test, y_train, y_test = train_test_split(df[\"text\"], df[\"satire\"], \n",
    "    test_size=0.2)\n",
    "vect = CountVectorizer(ngram_range=(1, 2),stop_words=None,lowercase=True,max_df=0.8, min_df=20)\n",
    "tfidf = TfidfTransformer()\n",
    "clf = LinearSVC(C=100.0)\n",
    "pipe_lr = Pipeline([\n",
    "    ('vect',vect),\n",
    "    ('tfidf',tfidf),\n",
    "    ('clf',clf)\n",
    "    ])\n",
    "pipe_lr.fit(text_train, y_train)\n",
    "print(len(vect.vocabulary_))\n",
    "\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(text_test,y_test))\n",
    "y_pred = pipe_lr.predict(text_test)\n",
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap='Greys', alpha=0.5)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72     MINNESOTA (The Borowitz Report)—Psychologists ...\n",
       "136    The campaign to rally support for Donald Trump...\n",
       "70     Now that Donald Trump is President and is assu...\n",
       "131    There were two notable Trumpworld headlines We...\n",
       "81     President-elect Donald Trump escalated his rhe...\n",
       "27     WASHINGTON (The Borowitz Report)—In an Oval Of...\n",
       "68     Me: Mr. Trump, you have recently said that you...\n",
       "106    Two years ago, Jonathan Clark was sending his ...\n",
       "97     Kentucky Sen. Rand Paul gave an indication tod...\n",
       "80     The Obama administration is preparing to annou...\n",
       "77     Donald Trump appears to have not a clue how to...\n",
       "43     FARMVILLE, VIRGINIA (The Borowitz Report)—The ...\n",
       "84     President-elect Donald Trump took to Twitter M...\n",
       "102    Two Senate Republicans joined demands for a bi...\n",
       "22     RICHMOND, VA (SatireWire.com) – Donald Trump’s...\n",
       "28     NEW YORK (The Borowitz Report)—A once-prominen...\n",
       "135    The search warrant that authorized the FBI to ...\n",
       "71     In light of the fact that a huge swath of whit...\n",
       "100    Bill English, New Zealand’s finance minister a...\n",
       "52     ST. LOUIS—Saying he hoped the Republican nomin...\n",
       "63     Bengaluru: Recently one Karnataka minister was...\n",
       "51     WEST PALM BEACH, FL—Responding to his flagging...\n",
       "139    Donald Trump’s transition team is asking State...\n",
       "35     NEW YORK, NY—During his Sunday interview with ...\n",
       "95     Senate Democrats dropped their objections Frid...\n",
       "87     Labor Secretary Tom Perez called presidential ...\n",
       "8      TORONTO – The emergence of EQAO test results t...\n",
       "4      NERCHINSK, RUSSIA—Quickly unlocking one cell d...\n",
       "79     As Donald Trump's 20 January inauguration draw...\n",
       "32     RALEIGH (The Borowitz Report)—Delivering her c...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "modelxgb=XGBClassifier()\n",
    "print(type(text_test))\n",
    "\n",
    "text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.iloc[:,:-1],df.iloc[:,-1]\n",
    "\n",
    "# import category_encoders as ce\n",
    "# # encode all features using ordinal encoding\n",
    "# encoder_x = ce.OrdinalEncoder()\n",
    "# X_encoded = encoder_x.fit_transform(X)\n",
    "\n",
    "# # you'll need to use a different encoder for each dataframe\n",
    "# encoder_y = ce.OrdinalEncoder()\n",
    "# y_encoded = encoder_y.fit_transform(y)\n",
    "\n",
    "# split encoded dataset\n",
    "# X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(X_encoded, y_encoded)\n",
    "# text_train, text_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train=text_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76        16\n",
      "           1       1.00      0.29      0.44        14\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.81      0.64      0.60        30\n",
      "weighted avg       0.79      0.67      0.61        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#naive_bayes\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(text_train, y_train)\n",
    "\n",
    "# %%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(text_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "###xbboost cant work directly with string we must  vectorize string first\n",
    "# modelxgb.fit(text_train, y_train)\n",
    "# print(len(vect.vocabulary_))\n",
    "\n",
    "# print('Test Accuracy: %.3f' % modelxgb.score(text_test,y_test))\n",
    "# y_pred = modelxgb.predict(text_test)\n",
    "# print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "# confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "# print(confmat)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "# ax.matshow(confmat, cmap='Greys', alpha=0.5)\n",
    "# for i in range(confmat.shape[0]):\n",
    "#     for j in range(confmat.shape[1]):\n",
    "#         ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "# plt.xlabel('predicted label')\n",
    "# plt.ylabel('true label')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('./confusion_matrix.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp1=pd.DataFrame({'title':y,'satire':1})\n",
    "dpr1=pd.DataFrame({'title':yr,'satire':0})\n",
    "df1 = pd.concat([dp1, dpr1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# text_train, text_test, y_train, y_test = train_test_split(df1[\"title\"], df1[\"satire\"], \n",
    "#     test_size=0.2, random_state=42)\n",
    "# vect = CountVectorizer(ngram_range=(1, 2),stop_words=None,lowercase=True,max_df=0.8, min_df=20)\n",
    "# tfidf = TfidfTransformer()\n",
    "# clf = LinearSVC(C=100.0)\n",
    "# pipe_lr = Pipeline([\n",
    "#     ('vect',vect),\n",
    "#     ('tfidf',tfidf),\n",
    "#     ('clf',clf)\n",
    "#     ])\n",
    "# pipe_lr.fit(text_train, y_train)\n",
    "\n",
    "# print(len(vect.vocabulary_))\n",
    "\n",
    "# print('Test Accuracy: %.3f' % pipe_lr.score(text_test,y_test))\n",
    "# y_pred = pipe_lr.predict(text_test)\n",
    "# print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "# confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "# print(confmat)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "# ax.matshow(confmat, cmap='Greys', alpha=0.5)\n",
    "# for i in range(confmat.shape[0]):\n",
    "#     for j in range(confmat.shape[1]):\n",
    "#         ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "# plt.xlabel('predicted label')\n",
    "# plt.ylabel('true label')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('./confusion_matrix.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returndata(path,i):\n",
    "    df=pd.read_csv(path)\n",
    "    df[\"class\"]=i\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import string\n",
    "def openfile(path):\n",
    "    file= open(path, 'r')\n",
    "    data = file.read().replace('\\n', '')\n",
    "    data=data.split(\"******\")\n",
    "#   clean(data)\n",
    "    df=pd.DataFrame(data)\n",
    "    df[\"class\"]=0\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=openfile(\"data/text/satire/satire_train.txt\")\n",
    "df2=openfile(\"data/text/satire/satire_test.txt\")\n",
    "df3=openfile(\"data/text/satire/satire_dev.txt\")\n",
    "df=pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CONCORD , NH After receiving \" subpar \" servic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MODESTO , CA Speaking with reporters before a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PINE BLUFF , AR Lee Brandt , 11 , a fifth grad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GAHANNA , OH Talking about how fun it will be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ORLANDO , FL Disgusted with the total childish...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3099</td>\n",
       "      <td>AFL CIO President Richard Trumka says Donald T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>Presidential candidate Chris Christie took a f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3101</td>\n",
       "      <td>Brice Callaway , a wannabe muslim and who now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3102</td>\n",
       "      <td>Guess which jackass would LOSE money if Trump ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3103</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16252 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  class\n",
       "0     CONCORD , NH After receiving \" subpar \" servic...      1\n",
       "1     MODESTO , CA Speaking with reporters before a ...      1\n",
       "2     PINE BLUFF , AR Lee Brandt , 11 , a fifth grad...      1\n",
       "3     GAHANNA , OH Talking about how fun it will be ...      1\n",
       "4     ORLANDO , FL Disgusted with the total childish...      1\n",
       "...                                                 ...    ...\n",
       "3099  AFL CIO President Richard Trumka says Donald T...      1\n",
       "3100  Presidential candidate Chris Christie took a f...      1\n",
       "3101  Brice Callaway , a wannabe muslim and who now ...      1\n",
       "3102  Guess which jackass would LOSE money if Trump ...      1\n",
       "3103                                                         1\n",
       "\n",
       "[16252 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=openfile(\"data/text/true/true_train_6.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16879 entries, 0 to 16878\n",
      "Data columns (total 2 columns):\n",
      "0        16879 non-null object\n",
      "class    16879 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 263.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row=pd.concat([df2,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row=df_row.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       CONCORD , NH After receiving \" subpar \" servic...\n",
       "1       MODESTO , CA Speaking with reporters before a ...\n",
       "2       PINE BLUFF , AR Lee Brandt , 11 , a fifth grad...\n",
       "3       GAHANNA , OH Talking about how fun it will be ...\n",
       "4       ORLANDO , FL Disgusted with the total childish...\n",
       "                              ...                        \n",
       "3099    AFL CIO President Richard Trumka says Donald T...\n",
       "3100    Presidential candidate Chris Christie took a f...\n",
       "3101    Brice Callaway , a wannabe muslim and who now ...\n",
       "3102    Guess which jackass would LOSE money if Trump ...\n",
       "3103                                                     \n",
       "Name: 0, Length: 16252, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8742001690208862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      4259\n",
      "           1       0.86      0.88      0.87      4024\n",
      "\n",
      "    accuracy                           0.87      8283\n",
      "   macro avg       0.87      0.87      0.87      8283\n",
      "weighted avg       0.87      0.87      0.87      8283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#naive_bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df_row[0]\n",
    "y = df_row[\"class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# %%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hedi\\.conda\\envs\\factory619\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.8,\n",
       "                                 max_features=None, min_df=20,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=50.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44039\n",
      "Test Accuracy: 0.948\n",
      "Precision: 0.949\n",
      "Recall: 0.945\n",
      "F1: 0.947\n",
      "[[3235  164]\n",
      " [ 179 3049]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e5b9be6fc8>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0, '3235')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(1, 0, '164')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 1, '179')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(1, 1, '3049')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'predicted label')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'true label')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#low range of data so still in process\n",
    "\n",
    "text_train, text_test, y_train, y_test = train_test_split(df_row[0], df_row[\"class\"], \n",
    "    test_size=0.2)\n",
    "vect = CountVectorizer(ngram_range=(1, 2),stop_words=None,lowercase=True,max_df=0.8, min_df=20)\n",
    "tfidf = TfidfTransformer()\n",
    "clf = LinearSVC(C=50.0)\n",
    "pipe_lr = Pipeline([\n",
    "    ('vect',vect),\n",
    "    ('tfidf',tfidf),\n",
    "    ('clf',clf)\n",
    "    ])\n",
    "pipe_lr.fit(text_train, y_train)\n",
    "print(len(vect.vocabulary_))\n",
    "\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(text_test,y_test))\n",
    "y_pred = pipe_lr.predict(text_test)\n",
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap='Greys', alpha=0.5)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192955 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df_row[0].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (33131, 250)\n"
     ]
    }
   ],
   "source": [
    "from  keras.preprocessing.sequence import pad_sequences\n",
    "X = tokenizer.texts_to_sequences(df_row[0].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (33131, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df_row['class']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29817, 250) (29817, 2)\n",
      "(3314, 250) (3314, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objs as go\n",
    "# import plotly.plotly as py\n",
    "import cufflinks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hedi\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26835 samples, validate on 2982 samples\n",
      "Epoch 1/5\n",
      "26835/26835 [==============================] - 133s 5ms/step - loss: 0.4710 - accuracy: 0.7952 - val_loss: 0.3609 - val_accuracy: 0.8625\n",
      "Epoch 2/5\n",
      "26835/26835 [==============================] - 175s 7ms/step - loss: 0.2202 - accuracy: 0.9257 - val_loss: 0.2008 - val_accuracy: 0.9292\n",
      "Epoch 3/5\n",
      "26835/26835 [==============================] - 190s 7ms/step - loss: 0.1287 - accuracy: 0.9582 - val_loss: 0.2377 - val_accuracy: 0.9108\n",
      "Epoch 4/5\n",
      "26835/26835 [==============================] - 187s 7ms/step - loss: 0.0878 - accuracy: 0.9723 - val_loss: 0.2956 - val_accuracy: 0.8944\n",
      "Epoch 5/5\n",
      "26835/26835 [==============================] - 170s 6ms/step - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.3166 - val_accuracy: 0.9178\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "# model.add(Bidirectional(LSTM(100)))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 250\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3314/3314 [==============================] - 4s 1ms/step\n",
      "Test set\n",
      "  Loss: 0.355\n",
      "  Accuracy: 0.906\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', '')\n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "df_row[0] = df_row[0].apply(clean_text)\n",
    "# df['Consumer complaint narrative'] = df['Consumer complaint narrative'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
